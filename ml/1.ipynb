{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.pyplot.style.use('seaborn')\n",
    "matplotlib.rcParams['figure.figsize'] = (15, 5)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=2, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import copy\n",
    "\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection, metrics, datasets\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "# $Model(x_i, w) = w_0 + \\sum_j^d w_j x_i^j$\n",
    "\n",
    "$x_i$ - $i'th$ featrue in matrix of features $X$\n",
    "\n",
    "$x_i^j$ - $j'th$ featrue value of current feature $i$\n",
    "\n",
    "$w_j$ - weight for $x_i^j$ feature value\n",
    "\n",
    "$w_0$ - free coeficent\n",
    "\n",
    "---\n",
    "\n",
    "In matrix (add $x_i^0$ and set it to $1$, and add $w_0$ for it)\n",
    "\n",
    "$Model(X, w) = Xw$\n",
    "\n",
    "$\\begin{bmatrix}\n",
    "(x_0^0=1), & ..., & (x_0^j) \\\\\n",
    "(x_1^0=1), & ..., & (x_1^j) \\\\\n",
    "... \\\\\n",
    "(x_n^0=1), & ..., & (x_n^j) \\\\\n",
    "\\end{bmatrix}$\n",
    "$\\begin{bmatrix}\n",
    "w_0 \\\\\n",
    "...\\\\\n",
    "w_j\n",
    "\\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = np.array([\n",
    "    [1, 2, 5],\n",
    "    [1, 5, 5],\n",
    "    [1, 8, 5],\n",
    "], dtype=np.float64)\n",
    "\n",
    "w = np.array([0.1, 0.1, 0.1], dtype=np.float64)\n",
    "\n",
    "yhat = X.dot(w)\n",
    "yhat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### $y = Xw + \\epsilon$\n",
    "\n",
    "$\\begin{bmatrix}\n",
    "y_0 \\\\\n",
    "... \\\\\n",
    "y_n \\\\\n",
    "\\end{bmatrix} = $\n",
    "$\\begin{bmatrix}\n",
    "x_0^0 & x_0^1 &  ... & x_0^j \\\\\n",
    "... \\\\\n",
    "x_n^0 & x_n^1 &  ... & x_n^j\n",
    "\\end{bmatrix}$\n",
    "$\\begin{bmatrix}\n",
    "w_0 \\\\\n",
    "...\\\\\n",
    "w_j\n",
    "\\end{bmatrix} +$\n",
    "$\\begin{bmatrix}\n",
    "\\epsilon_0 \\\\\n",
    "...\\\\\n",
    "\\epsilon_n\n",
    "\\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cost function (MSE)\n",
    "\n",
    "$Cost(w, X, y) = \\frac{1}{n} \\sum_i \\left(Model(x_i, w) - y_i \\right)^2$\n",
    "\n",
    "$Cost(w, X, y) = \\frac{1}{n}\\left\\| Xw-y \\right\\|^2$\n",
    "\n",
    "$\\triangledown Cost = \\frac{2}{n} X^{T}(Xw - y)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = np.array([\n",
    "    [1, 2, 15,  8],\n",
    "    [1, 5, 45, 12],\n",
    "    [1, 8, 53, 33],\n",
    "], dtype=np.float64)\n",
    "\n",
    "y = np.array([9, 21, 33], dtype=np.float64)\n",
    "w = np.array([0.1, 0.1, 0.1, 0.1], dtype=np.float64)\n",
    "\n",
    "error = np.linalg.norm(X.dot(w) - y)**2 / len(X)\n",
    "error\n",
    "\n",
    "sum((X.dot(w) - y)**2) / len(X)\n",
    "\n",
    "grad = (2/len(X)) * X.T.dot(X.dot(w) - y)\n",
    "grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cost function (RSS)\n",
    "\n",
    "$Cost(w, X, y) = \\sum_i \\left(y_i - \\sum_jx_i^jw_j \\right)^2$\n",
    "\n",
    "$Cost(w, X, y) = (y - Xw)^T(y - Xw)$\n",
    "\n",
    "$\\triangledown Cost = -2X^T(y - Xw)$\n",
    "\n",
    "_Intuition: (Not strong proof!)_\n",
    "\n",
    "* $\\frac{d}{dw} (y - Xw)^T(y - Xw) = \\frac{d}{dw} (y - Xw)^2 = 2(y - Xw)(y - Xw)' = 2(y - Xw)(-X) = -2X(y - Xw)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([\n",
    "    [1, 2, 15,  8],\n",
    "    [1, 5, 45, 12],\n",
    "    [1, 8, 53, 33],\n",
    "], dtype=np.float64)\n",
    "\n",
    "y = np.array([9, 21, 33], dtype=np.float64)\n",
    "w = np.array([0.1, 0.1, 0.1, 0.1], dtype=np.float64)\n",
    "\n",
    "error = (y - X.dot(w)).T.dot(y - X.dot(w))\n",
    "error\n",
    "\n",
    "grad = -2*X.T.dot(y - X.dot(w))\n",
    "grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task - Cost function minimization\n",
    "\n",
    "$Cost(w, X, y) \\Rightarrow \\underset{w}{min}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analytical solve (MSE)\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.linalg.inv(X.T.dot(X)).dot(X.T.dot(y))\n",
    "w "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analytical solve (RSS)\n",
    "\n",
    "$\\triangledown Cost = -2X^T(y - Xw) = 0$\n",
    "\n",
    "$-2X^T(y - Xw) = 0$\n",
    "\n",
    "$-2X^Ty + 2X^TXw = 0$\n",
    "\n",
    "$-X^Ty + X^TXw = 0$\n",
    "\n",
    "$X^TXw = X^Ty$\n",
    "\n",
    "$(X^TX)^{-1} X^TXw = (X^TX)^{-1} X^Ty$\n",
    "\n",
    "$(X^TX)^{-1} X^TX = I$, so: $w = (X^TX)^{-1} X^Ty$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.linalg.inv(X.T.dot(X)).dot(X.T.dot(y))\n",
    "w "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent (MSE)\n",
    "\n",
    "$w^t = w^{t-1} - \\alpha_t \\triangledown Cost(w^{t-1},X,y)$\n",
    "\n",
    "$\\triangledown$ - gradient _(vector of derivatives)_\n",
    "\n",
    "$\\alpha_t$ - learning rate for current step\n",
    "\n",
    "$t$ - iteration\n",
    "\n",
    "##### Stop: $\\left\\| w_t - w^{t-1} \\right\\| < \\epsilon$\n",
    "_если разница двух последовательных приближений не слишком велика_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Vector of derivatives (Gradient):\n",
    "\n",
    "Use chain rule:\n",
    "\n",
    "$\\frac{\\partial }{\\partial w_0} Cost =\n",
    "\\frac{1}{n} \\sum_i 2((w_0 + w_1 \\cdot x_i^{(1)} + w_2 \\cdot x_i^{(2)} + ... + w_j \\cdot x_i^{(j)}) - y_i) \\cdot 1\n",
    "$\n",
    "\n",
    "$\\frac{\\partial }{\\partial w_1} Cost =\n",
    "\\frac{1}{n} \\sum_i 2((w_0 + w_1 \\cdot x_i^{(1)} + w_2 \\cdot x_i^{(2)} + ... + w_j \\cdot x_i^{(j)}) - y_i) \\cdot x_i^{(1)}\n",
    "$\n",
    "\n",
    "$\\frac{\\partial }{\\partial w_j} Cost =\n",
    "\\frac{1}{n} \\sum_i 2((w_0 + w_1 \\cdot x_i^{(1)} + w_2 \\cdot x_i^{(2)} + ... + w_j \\cdot x_i^{(j)}) - y_i) \\cdot x_i^{(j)}\n",
    "$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Vectors of derivatives (Gradient):\n",
    "\n",
    "$\\triangledown Cost = \\begin{bmatrix}\n",
    "\\frac{2}{n} \\sum_i ((w_0 + w_1 \\cdot x_i^{(1)} + w_2 \\cdot x_i^{(2)} + ... + w_j \\cdot x_i^{(j)}) - y_i) \\cdot 1 \\\\\n",
    "\\frac{2}{n} \\sum_i ((w_0 + w_1 \\cdot x_i^{(1)} + w_2 \\cdot x_i^{(2)} + ... + w_j \\cdot x_i^{(j)}) - y_i) \\cdot x_i^{(1)} \\\\\n",
    "... \\\\\n",
    "\\frac{2}{n} \\sum_i ((w_0 + w_1 \\cdot x_i^{(1)} + w_2 \\cdot x_i^{(2)} + ... + w_j \\cdot x_i^{(j)}) - y_i) \\cdot x_i^{(j)}\n",
    "\\end{bmatrix}$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Vectors of derivatives (Gradient):\n",
    "\n",
    "$\\triangledown Cost = \\begin{bmatrix}\n",
    "\\frac{2}{n} (Xw - y) \\cdot 1 \\\\\n",
    "\\frac{2}{n} (Xw - y) \\cdot x^{(1)} \\\\\n",
    "... \\\\\n",
    "\\frac{2}{n} (Xw - y) \\cdot x^{(j)}\n",
    "\\end{bmatrix}$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Vectors of derivatives (Gradient):\n",
    "$\\triangledown Cost = \\frac{2}{n} X^{T}(Xw - y)$\n",
    "\n",
    "$X^T$ _is for_ \"$\\cdot x^{(j)}$\" on all $x_i$, see abowe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# . . ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MSE\n",
    "* $Cost(w, X, y) = \\frac{1}{n}\\left\\| Xw-y \\right\\|^2$\n",
    "* $\\triangledown Cost = \\frac{2}{n} X^{T}(Xw - y)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(w, X, y):\n",
    "    return np.linalg.norm(X.dot(w) - y)**2 / len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gmse(w, X, y):\n",
    "    return (2/len(X)) * X.T.dot(X.dot(w) - y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RSS\n",
    "* $Cost(w, X, y) = (y - Xw)^T(y - Xw)$\n",
    "* $\\triangledown Cost = -2X^T(y - Xw)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rss(w, X, y):\n",
    "    Xw = X.dot(w)\n",
    "    return (y - Xw).T.dot(y - Xw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grss(w, X, y):\n",
    "    return -2 * X.T.dot(y - X.dot(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# . . ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge (and rss cost)\n",
    "\n",
    "$Cost(w, X, y) = Cost(w, X, y) + \\lambda \\left\\| w \\right\\|_2^2 \\Rightarrow \\underset{w}{min}$\n",
    "\n",
    "$Cost(w, X, y) \\Rightarrow \\underset{w}{min}$\n",
    "\n",
    "$Cost(w, X, y) = (y - Xw)^T(y - Xw) + \\lambda \\left\\| w \\right\\|_2^2 =\n",
    "(y - Xw)^T(y - Xw) + \\lambda w^Tw\n",
    "$\n",
    "\n",
    "$\\triangledown Cost(w, X, y) =\n",
    "\\triangledown \\left[ (y - Xw)^T(y - Xw) + \\lambda w^Tw \\right] =\n",
    "\\triangledown \\left[ (y - Xw)^T(y - Xw) \\right] + \\triangledown  \\left[ \\lambda w^Tw \\right]\n",
    "$\n",
    "\n",
    "$\\triangledown Cost(w, X, y) = -2X^T(y - Xw) + 2\\lambda w\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge(w, l):\n",
    "    w = w.copy()\n",
    "    w[0] = 0 # Don’t penalize intercept term w0\n",
    "    return 2 * l * w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# . . ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimize(X, y, cost, grad, reg):\n",
    "    # add coef of ones\n",
    "    X = np.append(np.ones(len(X[0])), X.T).reshape(4,3).T\n",
    "\n",
    "    # weights vector\n",
    "    w = np.zeros(len(X[0]), dtype=np.float64)\n",
    "\n",
    "    # parameters\n",
    "    epsilon = 0.0\n",
    "    alpha = 0.1\n",
    "    weights = [w]\n",
    "    error = []\n",
    "\n",
    "    for iteration in range(500):\n",
    "        w = w - alpha * grad(w, X, y) - reg(w, 0.00001)\n",
    "        if np.linalg.norm(w - weights[-1]) < epsilon:\n",
    "            break\n",
    "        weights.append(w)\n",
    "        error.append(cost(w, X, y))\n",
    "\n",
    "    return w[0], w[1:], error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, w, coef):\n",
    "    X = np.append(np.ones(len(X[0])), X.T).reshape(4,3).T\n",
    "    w = np.append(np.array(coef), w)\n",
    "\n",
    "    return X.dot(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([\n",
    "    [0.2, 0.15, 0.8],\n",
    "    [0.5, 0.45, 0.12],\n",
    "    [0.8, 0.53, 0.33],\n",
    "], dtype=np.float64)\n",
    "\n",
    "y = np.array([\n",
    "    sum(X[0] * 2),\n",
    "    sum(X[1] * 2),\n",
    "    sum(X[2] * 2),\n",
    "], dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "coef, w, error = minimize(X, y, rss, grss, ridge)\n",
    "\n",
    "coef\n",
    "\n",
    "w\n",
    "predict(X, w, coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(error);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check analytically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wp = np.linalg.inv(X.T.dot(X)).dot(X.T.dot(y))\n",
    "\n",
    "wp\n",
    "X.dot(wp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check analytically with Ridge regularizator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 0.001*np.identity(len(X))\n",
    "wp = np.linalg.inv(X.T.dot(X) + L).dot(X.T.dot(y))\n",
    "\n",
    "wp\n",
    "X.dot(wp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check by sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "reg = LinearRegression().fit(X, y)\n",
    "\n",
    "reg.intercept_ \n",
    "\n",
    "reg.coef_\n",
    "reg.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
